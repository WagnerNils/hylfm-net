{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline \n",
    "# %matplotlib qt \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import yaml\n",
    "import os\n",
    "from scipy.ndimage import zoom, affine_transform\n",
    "import imageio\n",
    "import torch.nn\n",
    "from typing import Union, Tuple, List, Sequence, Optional, Any,OrderedDict\n",
    "import collections\n",
    "import numpy\n",
    "import torch.nn.functional\n",
    "from scipy.ndimage import affine_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/repos/lnet\")\n",
    "from lnet.utils.affine import inv_scipy_form2torch_form_2d, inv_scipy_form2torch_form_3d, scipy_form2torch_form_2d\n",
    "from lnet.setup import Stage\n",
    "from lnet.datasets.base import TensorInfo, get_dataset_from_info, ZipDataset, N5CachedDataset\n",
    "from lnet.transformations import AffineTransformation, Normalize01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lrds = get_dataset_from_info(TensorInfo(\n",
    "    \"lr\", \"lnet\", \"ref_data/AffineTransforms/SwipeThrough_-450_-210_nimages_241/Gcamp_dataset.h5/t[0-9]+/s00/0/cells\", transforms=[], meta={}, insert_singleton_axes_at=[0, 0]\n",
    "))\n",
    "lrds = N5CachedDataset(lrds)\n",
    "lsds = get_dataset_from_info(TensorInfo(\n",
    "    \"ls\", \"lnet\", \"ref_data/AffineTransforms/SwipeThrough_-450_-210_nimages_241/Gcamp_dataset.h5/t[0-9]+/s01/0/cells\", transforms=[], meta={}, insert_singleton_axes_at=[0, 0]\n",
    "))\n",
    "lsds = N5CachedDataset(lsds)\n",
    "ds = ZipDataset({\"lr\": lrds, \"ls\": lsds}, transformation=Normalize01(apply_to= [\"ls\", \"lr\"], min_percentile=0, max_percentile=100))\n",
    "only_lr_ds = ZipDataset({\"lr\": lrds}, transformation=Normalize01(apply_to= [\"lr\"], min_percentile=0, max_percentile=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ds[0]\n",
    "print('lr', sample[\"lr\"].shape)\n",
    "img_lr = sample[\"lr\"][0, 0].max(0)\n",
    "print('ls', sample[\"ls\"].shape)\n",
    "img_ls = sample[\"ls\"][0, 0].max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(img_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_form2torch_theta(scipy_form, ipt_shape, out_shape) -> torch.Tensor:\n",
    "    assert len(scipy_form.shape) == 2\n",
    "    assert not scipy_form[-1, :-1].any()    \n",
    "    assert scipy_form[-1, -1] == 1\n",
    "    norm_i = numpy.diag([2 / s for s in ipt_shape] + [1])\n",
    "    norm_i[:-1, -1] = -1\n",
    "    norm_o = numpy.diag(list(out_shape) + [2])\n",
    "    norm_o[:-1, -1] = out_shape\n",
    "    norm_o = norm_o / 2\n",
    "    scipy_normed = norm_i.dot(scipy_form).dot(norm_o)\n",
    "    assert not scipy_normed[-1, :-1].any()\n",
    "    \n",
    "    # transpose axis to match scipy implementation\n",
    "    theta4x4 = numpy.zeros_like(scipy_normed)\n",
    "    theta4x4[:-1, :-1] = scipy_normed[-2::-1, -2::-1]\n",
    "    theta4x4[:-1, -1] = scipy_normed[-2::-1, -1]\n",
    "    theta4x4[-1, -1] = scipy_normed[-1, -1]\n",
    "\n",
    "    # return with batch dimension as 1x3x4\n",
    "    return torch.from_numpy(theta4x4[None, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineTransformation(torch.nn.Module):\n",
    "    mode_from_order = {0: \"nearest\", 2: \"bilinear\"}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        apply_to: str,\n",
    "        target_to_compare_to: str,\n",
    "        order: int,\n",
    "        input_shape: Sequence[int],\n",
    "        matrices: List[List[float]],\n",
    "        output_shape: Sequence[int],\n",
    "        inverted: bool = False,\n",
    "        crop_out: Optional[Tuple[Tuple[int, int], ...]] = None,\n",
    "        crop_in: Optional[Tuple[Tuple[int, int], ...]] = None,\n",
    "    ):\n",
    "        if len(input_shape)  not in (2,3):\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if len(output_shape) not in (2,3):\n",
    "            raise NotImplementedError\n",
    "\n",
    "        super().__init__()\n",
    "        self.apply_to = apply_to\n",
    "        self.target_to_compare_to = target_to_compare_to\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "        self.mode = self.mode_from_order[order]\n",
    "\n",
    "        trf_matrix = self.concat_affine_matrices([self.bdv_trafo_to_affine_matrix(at) for at in matrices])\n",
    "        # self._forward_matrix = numpy.linalg.inv(matrix_with__forward_crop)\n",
    "        self.affine_grids = {}\n",
    "        # self.z_offset: int = self._forward_crop[0][0]\n",
    "\n",
    "        self.forward = self.inverted if inverted else self._forward\n",
    "        if crop_out is None:\n",
    "            self.order = 0\n",
    "            ones_out = self._impl(\n",
    "                numpy.ones((1, 1) + self.input_shape, dtype=numpy.uint8),\n",
    "                matrix=numpy.linalg.inv(trf_matrix),\n",
    "                trf_in_shape=self.input_shape,\n",
    "                trf_out_shape=self.output_shape,\n",
    "            )[0, 0]\n",
    "            dims = []\n",
    "            if len(ones_out.shape) == 3:\n",
    "                dims.append(ones_out.max(1).max(1))\n",
    "                ones_out_2d = ones_out.max(0)\n",
    "                dims.append(ones_out_2d.max(1))\n",
    "                dims.append(ones_out_2d.max(0))\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            crop_out = [(numpy.argmax(dim), -numpy.argmax(dim[::-1])) for dim in dims]\n",
    "            print(\"determined crop_out:\", crop_out)\n",
    "        elif len(crop_out) == len(output_shape) + 1:\n",
    "            assert crop_out[0][0] == 0 and crop_out[0][1] == 0, crop_out\n",
    "            crop_out = crop_out[1:]\n",
    "\n",
    "        if crop_in is None:\n",
    "            crop_in = tuple([(0, 0) for _ in range(len(input_shape))])\n",
    "        elif len(crop_in) == len(input_shape) + 1:\n",
    "            assert crop_in[0][0] == 0 and crop_in[0][1] == 0, crop_in\n",
    "            crop_in = crop_in[1:]\n",
    "\n",
    "        self.z_offset = crop_out[0][0]\n",
    "        self.cropped_output_shape = tuple(\n",
    "            [c[1] - c[0] if c[1] > 0 else outs - c[0] + c[1] for outs, c in zip(self.output_shape, crop_out)]\n",
    "        )\n",
    "        self.cropped_input_shape = tuple(\n",
    "            [c[1] - c[0] if c[1] > 0 else ins - c[0] + c[1] for ins, c in zip(self.input_shape, crop_in)]\n",
    "        )\n",
    "\n",
    "        self.order = order\n",
    "        crop_shift_out = numpy.eye(len(output_shape) + 1, dtype=trf_matrix.dtype)\n",
    "        crop_shift_out[:-1, -1] = [c[0] for c in crop_out]\n",
    "        crop_shift_in = numpy.eye(len(input_shape) + 1, dtype=trf_matrix.dtype)\n",
    "        crop_shift_in[:-1, -1] = [-c[0] for c in crop_in]\n",
    "        self.trf_matrix = crop_shift_in.dot(trf_matrix.dot(crop_shift_out))\n",
    "        self.inv_trf_matrix = numpy.linalg.inv(self.trf_matrix)\n",
    "      \n",
    "    @staticmethod\n",
    "    def bdv_trafo_to_affine_matrix(trafo):\n",
    "        \"\"\"from https://github.com/constantinpape/elf/blob/7b7cd21e632a07876a1302dad92f8d7c1929b37a/elf/transformation/affine.py#L162\n",
    "        Translate bdv transformation (XYZ) to affine matrix (ZYX)\n",
    "\n",
    "        \"\"\"\n",
    "        if len(trafo) == 12:\n",
    "            assert trafo[10] != 0.0\n",
    "            assert trafo[5] != 0.0\n",
    "            assert trafo[0] != 0.0\n",
    "            sub_matrix = numpy.zeros((3, 3))\n",
    "            sub_matrix[0, 0] = trafo[10]\n",
    "            sub_matrix[0, 1] = trafo[9]\n",
    "            sub_matrix[0, 2] = trafo[8]\n",
    "\n",
    "            sub_matrix[1, 0] = trafo[6]\n",
    "            sub_matrix[1, 1] = trafo[5]\n",
    "            sub_matrix[1, 2] = trafo[4]\n",
    "\n",
    "            sub_matrix[2, 0] = trafo[2]\n",
    "            sub_matrix[2, 1] = trafo[1]\n",
    "            sub_matrix[2, 2] = trafo[0]\n",
    "\n",
    "            shift = [trafo[11], trafo[7], trafo[3]]\n",
    "\n",
    "            matrix = numpy.zeros((4, 4))\n",
    "            matrix[:3, :3] = sub_matrix\n",
    "            matrix[:3, 3] = shift\n",
    "            matrix[3, 3] = 1\n",
    "\n",
    "            return matrix\n",
    "        elif len(trafo) == 6:\n",
    "            raise NotImplementedError(\"just a guess...\")\n",
    "            assert trafo[4] != 0.0\n",
    "            assert trafo[0] != 0.0\n",
    "            matrix = numpy.eye(3)\n",
    "            matrix[0, 0] = trafo[4]\n",
    "            matrix[0, 1] = trafo[3]\n",
    "            matrix[1, 0] = trafo[1]\n",
    "            matrix[1, 1] = trafo[0]\n",
    "            matrix[0, 2] = trafo[5]\n",
    "            matrix[1, 2] = trafo[2]\n",
    "            return matrix\n",
    "        else:\n",
    "            raise NotImplementedError(trafo)\n",
    "\n",
    "    @staticmethod\n",
    "    def concat_affine_matrices(matrices: List[numpy.ndarray]):\n",
    "#         assert all(m.shape == (4, 4) for m in matrices), [m.shape for m in matrices]\n",
    "        ret = matrices[0]\n",
    "        for m in matrices[1:]:\n",
    "            ret = ret.dot(m)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def get_affine_grid(scipy_form, ipt_shape, out_shape):\n",
    "        assert len(scipy_form.shape) == 2, scipy_form.shape\n",
    "        assert len(ipt_shape) in (2, 3)\n",
    "        assert len(ipt_shape) == len(out_shape), (ipt_shape, out_shape)\n",
    "        theta = scipy_form2torch_theta(scipy_form, ipt_shape, out_shape)\n",
    "        affine_grid_size = (1, 1) + tuple(out_shape)\n",
    "        return torch.nn.functional.affine_grid(theta=theta, size=affine_grid_size, align_corners=False)\n",
    "    \n",
    "    def _impl(\n",
    "        self,\n",
    "        img_shape,\n",
    "        ipt: Union[torch.Tensor, numpy.ndarray],\n",
    "        matrix: numpy.ndarray,\n",
    "        trf_in_shape: Tuple[int, ...],\n",
    "        trf_out_shape: Tuple[int, ...],\n",
    "        output_sampling_shape: Optional[Tuple[int, ...]] = None,\n",
    "        z_slices: Optional[Sequence[int]] = None,\n",
    "    ) -> Union[numpy.ndarray, torch.Tensor]:\n",
    "        print(\"img shape\", img_shape)\n",
    "        print(\"ipt shape\", ipt.shape)\n",
    "        print(\"trf in shape\", trf_in_shape)\n",
    "        print(\"trf out shape\", trf_out_shape)\n",
    "        print(\"out sampling shape\", output_sampling_shape)\n",
    "        if output_sampling_shape is None:\n",
    "            output_sampling_shape = trf_out_shape\n",
    "        elif z_slices is not None and any([zs is not None for zs in z_slices]):\n",
    "            raise ValueError(\"exclusive args: z_slices, output_sampling_shape\")\n",
    "\n",
    "\n",
    "        if trf_in_shape != ipt.shape[2:]:\n",
    "            in_scaling = [ipts / trf_in for ipts, trf_in in zip(ipt.shape[2:], trf_in_shape)] + [1.0]\n",
    "            print(\"ipt.shape -> trf_in_shape\", in_scaling)\n",
    "            matrix = matrix.dot(numpy.diag(in_scaling))\n",
    "\n",
    "        if trf_out_shape != output_sampling_shape:\n",
    "            out_scaling = [trf_out / outs for trf_out, outs in zip(trf_out_shape, output_sampling_shape)] + [1.0]\n",
    "            print(\"trf_out_shape -> output_sampling\", out_scaling)\n",
    "            matrix = numpy.diag(out_scaling).dot(matrix)\n",
    "            \n",
    "\n",
    "        if isinstance(ipt, numpy.ndarray):\n",
    "            assert len(ipt.shape) in [4, 5], ipt.shape\n",
    "            return numpy.stack([\n",
    "                numpy.stack([affine_transform(ipt_woc, matrix, output_shape=output_sampling_shape, order=self.order) for ipt_woc in ipt_wc]) for ipt_wc in ipt\n",
    "            ])\n",
    "        elif isinstance(ipt, torch.Tensor):\n",
    "            on_cuda = False\n",
    "            ipt_was_cuda = ipt.is_cuda\n",
    "            if on_cuda != ipt.is_cuda:\n",
    "                if on_cuda:\n",
    "                    ipt = ipt.to(torch.device(\"cuda:0\"))\n",
    "                else:\n",
    "                    ipt = ipt.to(torch.device(\"cpu\"))\n",
    "                    \n",
    "            affine_grid_key = (matrix.tostring(), ipt.shape[2:], output_sampling_shape)\n",
    "            affine_grid = self.affine_grids.get(affine_grid_key, None)\n",
    "            if affine_grid is None:\n",
    "                affine_grid = self.get_affine_grid(matrix, ipt.shape[2:], output_sampling_shape)\n",
    "                affine_grid.to(ipt)\n",
    "                self.affine_grids[affine_grid_key] = affine_grid\n",
    "\n",
    "            affine_grid = affine_grid.to(ipt)\n",
    "\n",
    "            if z_slices is None or all([zs is None for zs in z_slices]):\n",
    "                affine_grid = affine_grid.expand(ipt.shape[0], *([-1] * (len(ipt.shape) -1)))\n",
    "            else:\n",
    "                assert all([zs is not None for zs in z_slices]), z_slices\n",
    "                assert len(z_slices) == ipt.shape[0], (z_slices, ipt.shape)\n",
    "                assert all(self.z_offset <= z_slice for z_slice in z_slices), (self.z_offset, z_slices)\n",
    "                affine_grid = torch.cat(\n",
    "                    [\n",
    "                        self.affine_torch_grid[:, z_slice - self.z_offset : z_slice + 1 - self.z_offset]\n",
    "                        for z_slice in z_slices\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            ret = torch.nn.functional.grid_sample(\n",
    "                ipt, affine_grid, align_corners=False, mode=self.mode, padding_mode=\"zeros\"# \"border\"\n",
    "            )\n",
    "            if not (z_slices is None or all([zs is None for zs in z_slices])):\n",
    "                assert ret.shape[2] == 1, ret.shape\n",
    "                ret = ret[:, :, 0]\n",
    "\n",
    "            if on_cuda == ipt_was_cuda:\n",
    "                return ret\n",
    "            elif ipt_was_cuda:\n",
    "                return ret.to(device=torch.device(\"cuda:0\"))\n",
    "            else:\n",
    "                return ret.to(device=torch.device(\"cpu\"))\n",
    "        else:\n",
    "            raise TypeError(type(ipt))\n",
    "\n",
    "    def inverted(self, ipt: Union[torch.Tensor, numpy.ndarray], **kwargs) -> OrderedDict[str, Any]:\n",
    "        raise NotImplementedError\n",
    "        ipt = tensors[self.apply_to]\n",
    "        tgt = tensors[self.target_to_compare_to]\n",
    "\n",
    "        return self._impl(\n",
    "            ipt, matrix=self.trf_matrix, trf_in_shape=self.output_shape, trf_out_shape=self.input_shape, **kwargs\n",
    "        )\n",
    "\n",
    "    def _forward(self, img_shape, tensors: OrderedDict[str, Any]) -> OrderedDict[str, Any]:\n",
    "#         for meta in tensors[\"meta\"]:\n",
    "#             tmeta = meta[self.target_to_compare_to]\n",
    "#             assert tmeta[\"shape_before_resize\"][1:] == self.cropped_output_shape, (\n",
    "#                 tmeta[\"shape_before_resize\"],\n",
    "#                 self.cropped_output_shape,\n",
    "#             )\n",
    "\n",
    "#         output_sampling_shape = (\n",
    "#             None  # sample output as trf output and select z_slice (for 2d target) ...\n",
    "#             if len(tensors[self.target_to_compare_to].shape) == 4\n",
    "#             else tuple(tensors[self.target_to_compare_to].shape[2:])  # ...or resample output to compare to volumetric target\n",
    "#         )\n",
    "        tensors[self.apply_to] = self._impl(self.cropped_input_shape,\n",
    "            tensors[self.apply_to],\n",
    "            matrix=self.inv_trf_matrix,\n",
    "            trf_in_shape=self.cropped_input_shape,\n",
    "            trf_out_shape=self.cropped_output_shape,\n",
    "#             output_sampling_shape=(84, 133, 162),\n",
    "#             output_sampling_shape=(100, 200),\n",
    "            output_sampling_shape=(100, 200, 300),\n",
    "            z_slices=[m.get(\"z_slice\", None) for m in tensors[\"meta\"]],\n",
    "        )\n",
    "        return tensors\n",
    "    \n",
    "# trf = AffineTransformation(apply_to=\"lr\", target_to_compare_to=\"ls\", order=0, input_shape=(838, 1330, 1615), output_shape=(241, 1501, 1801), matrices=[[0.98048,0.004709,0.098297,-111.7542,7.6415e-05,0.97546,0.0030523,-20.1143,0.014629,8.2964e-06,-3.9928,846.8515]], crop_in=[(5, -5), (10, -10), (10, -10)], crop_out=[(3, -22), (20, -117), (87, -41)])\n",
    "# trf = AffineTransformation(apply_to=\"lr\", target_to_compare_to=\"ls\", order=0, input_shape=(838, 1330, 1615), output_shape=(241, 1501, 1801), matrices=[[0.98048,0.004709,0.098297,-111.7542,7.6415e-05,0.97546,0.0030523,-20.1143,0.014629,8.2964e-06,-3.9928,846.8515]], crop_in=[(0, 0), (0, 0), (0, 0)], crop_out=[(0, 0), (0, 0), (0, 0)])\n",
    "# trf = AffineTransformation(apply_to=\"lr\", target_to_compare_to=\"ls\", order=0, input_shape=(838, 1330, 1615), output_shape=(241, 1501, 1801), matrices=[[0.98048,0.004709,0.098297,-111.7542,7.6415e-05,0.97546,0.0030523,-20.1143,0.014629,8.2964e-06,-3.9928,846.8515]], crop_in=[(0, 0), (-50, 50), (0, 0)], crop_out=[(0, 0), (0, 0), (0, 0)])\n",
    "# trf = AffineTransformation(apply_to=\"lr\", target_to_compare_to=\"ls\", order=0, input_shape=(1330, 1615), output_shape=(1501, 1801), matrices=[[0.98048,0.004709,-111.7542,7.6415e-05,0.97546,-20.1143]], crop_in=[(0, 0), (0, 0)], crop_out=[(0, 0), (0, 0)])\n",
    "# trf = AffineTransformation(apply_to=\"lr\", target_to_compare_to=\"ls\", order=0, input_shape=(100, 200), output_shape=(100, 200), matrices=[[1.0, 0.0, 0.0 , 0.0, 1.0, 10.0]], crop_in=[(0, 0), (0, 0)], crop_out=[(0, 0), (0, 0)])\n",
    "trf = AffineTransformation(apply_to=\"lr\", target_to_compare_to=\"ls\", order=0, input_shape=(100, 200, 300), output_shape=(100, 200, 300), matrices=[[.5, 0.0, 0.0, 0.0 , 0.0, .5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]], crop_in=[(0, 0), (50, 0), (0, 0)], crop_out=[(0, 0), (0, 0), (0, 0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_ipt = only_lr_ds[0][\"lr\"][:, :, 5:-5, 10:-10, 10:-10]\n",
    "ipt_size = (1, 1, 100, 200, 300)\n",
    "lr_ipt = numpy.ones(ipt_size, dtype=\"float64\")\n",
    "img_shape = None\n",
    "out_torch = trf(img_shape, {\"lr\": torch.from_numpy(lr_ipt).cuda(), \"meta\": [{}]})[\"lr\"][0, 0].cpu().numpy()\n",
    "\n",
    "lr_ipt = numpy.ones(ipt_size, dtype=\"float64\")\n",
    "out = trf(img_shape, {\"lr\": lr_ipt, \"meta\": [{}]})[\"lr\"][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.shape, out_torch.shape)\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(30, 10))\n",
    "\n",
    "for i in range(3):\n",
    "    out_img = out.max(i)\n",
    "    out_torch_img = out_torch.max(i)\n",
    "    img = numpy.zeros_like(out_img)\n",
    "    img[::2, ::2] = out_img[::2, ::2]\n",
    "    img[1::2, 1::2] = out_img[1::2, 1::2]\n",
    "    img[::2, 1::2] = -out_torch_img[::2, 1::2]\n",
    "    img[1::2, ::2] = -out_torch_img[1::2, ::2]\n",
    "    ax[i].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_ipt = only_lr_ds[0][\"lr\"][:, :, 5:-5, 10:-10, 10:-10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(out_torch.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(out_torch.max(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(out.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(out.max(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_ones = trf({\"lr\": numpy.ones((1, 1, 49, 1330, 1615))}, select_output_shape=(241, 1501, 1801))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ones[0, 0].max(0).max(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1501- 117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.argmax(out_ones[0, 0].max(0).max(1)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ones[0, 0].max(0).max(1)[1383:1384+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trf(sample, select_output_shape=(24, 150, 180))[\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.min(), out.max(), out.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(out[0, 0].max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(out[0, 0].max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(sample[\"ls\"][0, 0].max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(sample[\"ls\"][0, 0].max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "# nout = out / out.max()\n",
    "# inn = sample[\"ls\"] / sample[\"ls\"].max()\n",
    "# plt.imshow(numpy.stack([nout.max(0)], axis=2))\n",
    "plt.imshow(nout[0, 0].max(0) - inn[0, 0].max(0))\n",
    "# plt.imshow((nout - inn).max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow((nout - inn)[0, 0].max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.max(), out.min(), out.dtype)\n",
    "out16 = (out.astype(\"float32\") + 32768).astype(\"uint16\")\n",
    "print(out16.max(), out16.min(), out16.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.volwrite(\"ref_data/AffineTransforms/SwipeThrough_-450_-210_nimages_241/out.tif\", out16[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDVTransform(torch.nn.Module):\n",
    "    mode_from_order = {0: \"nearest\", 2: \"bilinear\"}\n",
    "\n",
    "    # to be set by subclass\n",
    "    ls_shape: Union[Tuple[int, int], Tuple[int, int, int]]\n",
    "    lf2ls_crop: Union[Tuple[Tuple[int, int], Tuple[int, int]], Tuple[Tuple[int, int], Tuple[int, int], Tuple[int, int]]]\n",
    "    lf_shape: Union[Tuple[int, int], Tuple[int, int, int]]\n",
    "    affine_transforms: Tuple[Tuple[float]]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        order: int = 0,\n",
    "        additional_transforms_left: Sequence[numpy.ndarray] = tuple(),\n",
    "        additional_transforms_right: Sequence[numpy.ndarray] = tuple(),\n",
    "        forward: str = \"lf2ls\",\n",
    "        trf_out_zoom: Tuple[float, float, float] = (1.0, 1.0, 1.0),\n",
    "        lf_shape: Optional[Tuple[int, int, int]] = None,\n",
    "    ):\n",
    "        if output_shape is not None and len(output_shape) == 2:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # check if correctly inherited\n",
    "        assert hasattr(self, \"affine_transforms\") and isinstance(self.affine_transforms, tuple)\n",
    "        assert hasattr(self, \"ls_shape\") and isinstance(self.ls_shape, tuple)\n",
    "        assert hasattr(self, \"lf2ls_crop\") and isinstance(self.lf2ls_crop, tuple)\n",
    "        assert hasattr(self, \"lf_shape\") and isinstance(self.lf_shape, tuple)\n",
    "\n",
    "        if lf_shape is not None:\n",
    "            self.lf_shape = lf_shape\n",
    "\n",
    "        assert forward in [\"lf2ls\", \"ls2lf\"]\n",
    "        self.forward = getattr(self, forward)\n",
    "        super().__init__()\n",
    "        self.trf_out_zoom = trf_out_zoom\n",
    "        assert output_shape is None or isinstance(output_shape, tuple)\n",
    "        self.mode = self.mode_from_order.get(order, None)\n",
    "\n",
    "        self.trf_matrix = self.concat_affine_matrices(\n",
    "            list(additional_transforms_left)\n",
    "            + [self.bdv_trafo_to_affine_matrix(at) for at in self.affine_transforms]\n",
    "            + list(additional_transforms_right)\n",
    "        )\n",
    "        self.inv_trf_matrix = numpy.linalg.inv(self.trf_matrix)\n",
    "        lf2ls_crop_shift = numpy.eye(len(self.ls_shape) + 1, dtype=self.trf_matrix.dtype)\n",
    "        lf2ls_crop_shift[:-1, -1] = [c[0] for c in self.lf2ls_crop]\n",
    "        matrix_with_lf2ls_crop = self.trf_matrix.dot(lf2ls_crop_shift)\n",
    "        self.lf2ls_matrix = numpy.linalg.inv(matrix_with_lf2ls_crop)\n",
    "        self.output_shape = output_shape\n",
    "        self.order = order\n",
    "        self.affine_grid_size = None\n",
    "        self.z_offset: int = self.lf2ls_crop[0][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def bdv_trafo_to_affine_matrix(trafo):\n",
    "        \"\"\" Translate bdv transformation (XYZ) to affine matrix (ZYX)\n",
    "        \"\"\"\n",
    "        assert len(trafo) == 12\n",
    "\n",
    "        assert trafo[10] != 0.0\n",
    "        assert trafo[5] != 0.0\n",
    "        assert trafo[0] != 0.0\n",
    "        sub_matrix = numpy.zeros((3, 3))\n",
    "        sub_matrix[0, 0] = trafo[10]\n",
    "        sub_matrix[0, 1] = trafo[9]\n",
    "        sub_matrix[0, 2] = trafo[8]\n",
    "\n",
    "        sub_matrix[1, 0] = trafo[6]\n",
    "        sub_matrix[1, 1] = trafo[5]\n",
    "        sub_matrix[1, 2] = trafo[4]\n",
    "\n",
    "        sub_matrix[2, 0] = trafo[2]\n",
    "        sub_matrix[2, 1] = trafo[1]\n",
    "        sub_matrix[2, 2] = trafo[0]\n",
    "\n",
    "        shift = [trafo[11], trafo[7], trafo[3]]\n",
    "\n",
    "        matrix = numpy.zeros((4, 4))\n",
    "        matrix[:3, :3] = sub_matrix\n",
    "        matrix[:3, 3] = shift\n",
    "        matrix[3, 3] = 1\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def concat_affine_matrices(matrices: List[numpy.ndarray]):\n",
    "        assert all(m.shape == (4, 4) for m in matrices), [m.shape for m in matrices]\n",
    "        ret = matrices[0]\n",
    "        for m in matrices[1:]:\n",
    "            ret = ret.dot(m)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _ls2lf(\n",
    "        self,\n",
    "        ipt: Union[torch.Tensor, numpy.ndarray],\n",
    "        matrix: numpy.ndarray,\n",
    "        trf_in_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        trf_out_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        output_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        order: Optional[int] = None,\n",
    "        z_slices: Optional[Sequence[int]] = None,\n",
    "    ) -> Union[numpy.ndarray, torch.Tensor]:\n",
    "        output_shape = output_shape or self.output_shape\n",
    "        order = order or self.order\n",
    "        mode = self.mode_from_order[order]\n",
    "        if isinstance(ipt, numpy.ndarray):\n",
    "            assert len(ipt.shape) == 3, ipt.shape\n",
    "            if trf_in_shape != ipt.shape:\n",
    "                in_scaling = [trf_in / ipts for ipts, trf_in in zip(ipt.shape, trf_in_shape)] + [1.0]\n",
    "                matrix = matrix.dot(numpy.diag(in_scaling))\n",
    "\n",
    "            if trf_out_shape != output_shape:\n",
    "                out_scaling = [outs / trf_out for trf_out, outs in zip(trf_out_shape, output_shape)] + [1.0]\n",
    "                matrix = numpy.diag(out_scaling).dot(matrix)\n",
    "\n",
    "            return affine_transform(ipt, numpy.linalg.inv(matrix), output_shape=output_shape, order=order)\n",
    "        elif isinstance(ipt, torch.Tensor):\n",
    "            if len(ipt.shape) == 4:\n",
    "                torch_form = inv_scipy_form2torch_form_2d(\n",
    "                    matrix,\n",
    "                    ipt_shape=ipt.shape[2:],\n",
    "                    trf_in_shape=trf_in_shape,\n",
    "                    trf_out_shape=trf_out_shape,\n",
    "                    out_shape=output_shape,\n",
    "                )\n",
    "            elif len(ipt.shape) == 5:\n",
    "                torch_form = inv_scipy_form2torch_form_3d(\n",
    "                    matrix,\n",
    "                    ipt_shape=ipt.shape[2:],\n",
    "                    trf_in_shape=trf_in_shape,\n",
    "                    trf_out_shape=trf_out_shape,\n",
    "                    out_shape=output_shape,\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(ipt.shape)\n",
    "\n",
    "            # affine_grid_size = tuple(ipt.shape[:2]) + output_shape\n",
    "            affine_grid_size = (1, 1) + output_shape\n",
    "            if self.affine_grid_size != affine_grid_size:\n",
    "                self.affine_torch_grid = torch.nn.functional.affine_grid(\n",
    "                    theta=torch_form, size=affine_grid_size, align_corners=False\n",
    "                )\n",
    "\n",
    "            on_cuda = ipt.is_cuda\n",
    "            if on_cuda != ipt.is_cuda:\n",
    "                if on_cuda:\n",
    "                    ipt = ipt.to(torch.device(\"cuda:0\"))\n",
    "                else:\n",
    "                    ipt = ipt.to(torch.device(\"cpu\"))\n",
    "\n",
    "            self.affine_torch_grid = self.affine_torch_grid.to(ipt)\n",
    "\n",
    "            if z_slices is None:\n",
    "                affine_grid = self.affine_torch_grid.repeat(ipt.shape[0], 1, 1, 1, 1)\n",
    "            else:\n",
    "                assert len(z_slices) == ipt.shape[0], (z_slices, ipt.shape)\n",
    "                assert all(self.z_offset <= z_slice for z_slice in z_slices), (self.z_offset, z_slices)\n",
    "                affine_grid = torch.cat(\n",
    "                    [\n",
    "                        self.affine_torch_grid[:, z_slice - self.z_offset : z_slice + 1 - self.z_offset]\n",
    "                        for z_slice in z_slices\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            ret = torch.nn.functional.grid_sample(\n",
    "                ipt, affine_grid, align_corners=False, mode=mode, padding_mode=\"border\"\n",
    "            )\n",
    "            if z_slices is not None:\n",
    "                assert ret.shape[2] == 1\n",
    "                ret = ret[:, :, 0]\n",
    "\n",
    "            if on_cuda == ipt.is_cuda:\n",
    "                return ret\n",
    "            elif ipt.is_cuda:\n",
    "                return ret.to(device=torch.device(\"cuda:0\"))\n",
    "            else:\n",
    "                return ret.to(device=torch.device(\"cpu\"))\n",
    "        else:\n",
    "            raise TypeError(type(ipt))\n",
    "\n",
    "    def ls2lf(self, ipt: Union[torch.Tensor, numpy.ndarray], **kwargs) -> Union[numpy.ndarray, torch.Tensor]:\n",
    "        raise NotImplementedError(\"trf_out_zoom\")\n",
    "        return self._ls2lf(\n",
    "            ipt, matrix=self.trf_matrix, trf_in_shape=self.ls_shape, trf_out_shape=self.lf_shape, **kwargs\n",
    "        )\n",
    "\n",
    "    def lf2ls(self, ipt: Union[torch.Tensor, numpy.ndarray], **kwargs) -> Union[numpy.ndarray, torch.Tensor]:\n",
    "        cropped_ls_shape: Union[Tuple[int, int], Tuple[int, int, int]] = tuple(\n",
    "            (lss - ls_crop[0] - ls_crop[1]) * zoom\n",
    "            for lss, ls_crop, zoom in zip(self.ls_shape, self.lf2ls_crop, self.trf_out_zoom)\n",
    "        )\n",
    "        return self._ls2lf(\n",
    "            ipt, matrix=self.lf2ls_matrix, trf_in_shape=self.lf_shape, trf_out_shape=cropped_ls_shape, **kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "class TestTransform(BDVTransform):\n",
    "    affine_transforms = ((0.98048,0.004709,0.098297,-111.7542,7.6415e-05,0.97546,0.0030523,-20.1143,0.014629,8.2964e-06,-3.9928,846.8515),)\n",
    "#     lf2ls_crop = ((3, 22), (20, 117), (87, 41))\n",
    "    lf2ls_crop = ((0, 0), (0, 0), (0, 0))\n",
    "    ls_shape = (241, 1501, 1801)\n",
    "    lf_shape = (838, 1330, 1615)\n",
    "    \n",
    "test_trf = TestTransform(order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipt = test_sample[\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = test_trf(ipt[0, 0], output_shape=(49, 130, 180))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(test_out.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_ipt = torch.from_numpy(ipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_test_out = test_trf(torch_ipt, output_shape=(49, 1300, 1800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(torch_test_out[0, 0].cpu().numpy().max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(torch_test_out[0, 0].cpu().numpy().max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(test_out.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDVTransform(torch.nn.Module):\n",
    "    mode_from_order = {0: \"nearest\", 2: \"bilinear\"}\n",
    "\n",
    "    # to be set by subclass\n",
    "    ls_shape: Union[Tuple[int, int], Tuple[int, int, int]]\n",
    "    lf2ls_crop: Union[Tuple[Tuple[int, int], Tuple[int, int]], Tuple[Tuple[int, int], Tuple[int, int], Tuple[int, int]]]\n",
    "    lf_shape: Union[Tuple[int, int], Tuple[int, int, int]]\n",
    "    affine_transforms: Tuple[Tuple[float]]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        forward: str,\n",
    "        order: int,\n",
    "        output_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        additional_transforms_left: Sequence[numpy.ndarray] = tuple(),\n",
    "        additional_transforms_right: Sequence[numpy.ndarray] = tuple(),\n",
    "        trf_out_zoom: Tuple[float, float, float] = (1.0, 1.0, 1.0),\n",
    "        lf_shape: Optional[Tuple[int, int, int]] = None,\n",
    "    ):\n",
    "        # check if correctly inherited\n",
    "#         assert hasattr(self, \"affine_transforms\") and isinstance(self.affine_transforms, tuple), self.affine_transforms\n",
    "        assert hasattr(self, \"ls_shape\") and isinstance(self.ls_shape, tuple), self.ls_shape\n",
    "        assert hasattr(self, \"lf2ls_crop\") and isinstance(self.lf2ls_crop, tuple), self.lf2ls_crop\n",
    "        assert hasattr(self, \"lf_shape\") and isinstance(self.lf_shape, tuple), self.lf_shape\n",
    "\n",
    "        if forward == \"lf2ls\":\n",
    "            self.forward = self.lf2ls\n",
    "        elif forward == \"ls2lf\":\n",
    "            self.forward = self.ls2lf\n",
    "        else:\n",
    "            raise NotImplementedError(forward)\n",
    "\n",
    "        super().__init__()\n",
    "        assert output_shape is None or isinstance(output_shape, tuple)\n",
    "        if output_shape is not None and len(output_shape) == 2:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "        if lf_shape is not None:\n",
    "            self.lf_shape = lf_shape\n",
    "\n",
    "        self.trf_out_zoom = trf_out_zoom\n",
    "        self.mode = self.mode_from_order.get(order, None)\n",
    "\n",
    "        self.trf_matrix = self.concat_affine_matrices(\n",
    "            list(additional_transforms_left)\n",
    "            + [self.bdv_trafo_to_affine_matrix(at) for at in self.affine_transforms]\n",
    "            + list(additional_transforms_right)\n",
    "        )\n",
    "        self.inv_trf_matrix = numpy.linalg.inv(self.trf_matrix)\n",
    "        lf2ls_crop_shift = numpy.eye(len(self.ls_shape) + 1, dtype=self.trf_matrix.dtype)\n",
    "        lf2ls_crop_shift[:-1, -1] = [c[0] for c in self.lf2ls_crop]\n",
    "        matrix_with_lf2ls_crop = self.trf_matrix.dot(lf2ls_crop_shift)\n",
    "        self.lf2ls_matrix = numpy.linalg.inv(matrix_with_lf2ls_crop)\n",
    "        self.order = order\n",
    "        self.affine_grid_size = None\n",
    "        self.z_offset: int = self.lf2ls_crop[0][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def bdv_trafo_to_affine_matrix(trafo):\n",
    "        \"\"\" Translate bdv transformation (XYZ) to affine matrix (ZYX)\n",
    "        \"\"\"\n",
    "        assert len(trafo) == 12\n",
    "\n",
    "        assert trafo[10] != 0.0\n",
    "        assert trafo[5] != 0.0\n",
    "        assert trafo[0] != 0.0\n",
    "        sub_matrix = numpy.zeros((3, 3))\n",
    "        sub_matrix[0, 0] = trafo[10]\n",
    "        sub_matrix[0, 1] = trafo[9]\n",
    "        sub_matrix[0, 2] = trafo[8]\n",
    "\n",
    "        sub_matrix[1, 0] = trafo[6]\n",
    "        sub_matrix[1, 1] = trafo[5]\n",
    "        sub_matrix[1, 2] = trafo[4]\n",
    "\n",
    "        sub_matrix[2, 0] = trafo[2]\n",
    "        sub_matrix[2, 1] = trafo[1]\n",
    "        sub_matrix[2, 2] = trafo[0]\n",
    "\n",
    "        shift = [trafo[11], trafo[7], trafo[3]]\n",
    "\n",
    "        matrix = numpy.zeros((4, 4))\n",
    "        matrix[:3, :3] = sub_matrix\n",
    "        matrix[:3, 3] = shift\n",
    "        matrix[3, 3] = 1\n",
    "\n",
    "        return matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def concat_affine_matrices(matrices: List[numpy.ndarray]):\n",
    "        assert all(m.shape == (4, 4) for m in matrices), [m.shape for m in matrices]\n",
    "        ret = matrices[0]\n",
    "        for m in matrices[1:]:\n",
    "            ret = ret.dot(m)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _ls2lf(\n",
    "        self,\n",
    "        ipt: Union[torch.Tensor, numpy.ndarray],\n",
    "        matrix: numpy.ndarray,\n",
    "        trf_in_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        trf_out_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        output_shape: Optional[Union[Tuple[int, int], Tuple[int, int, int]]] = None,\n",
    "        order: Optional[int] = None,\n",
    "        z_slices: Optional[Sequence[int]] = None,\n",
    "    ) -> Union[numpy.ndarray, torch.Tensor]:\n",
    "        output_shape = output_shape or self.output_shape\n",
    "        order = order or self.order\n",
    "        mode = self.mode_from_order[order]\n",
    "        if isinstance(ipt, numpy.ndarray):\n",
    "            assert len(ipt.shape) == 3, ipt.shape\n",
    "            if trf_in_shape != ipt.shape:\n",
    "                in_scaling = [trf_in / ipts for ipts, trf_in in zip(ipt.shape, trf_in_shape)] + [1.0]\n",
    "                matrix = matrix.dot(numpy.diag(in_scaling))\n",
    "\n",
    "            if trf_out_shape != output_shape:\n",
    "                out_scaling = [outs / trf_out for trf_out, outs in zip(trf_out_shape, output_shape)] + [1.0]\n",
    "                matrix = numpy.diag(out_scaling).dot(matrix)\n",
    "\n",
    "            return affine_transform(ipt, numpy.linalg.inv(matrix), output_shape=output_shape, order=order)\n",
    "        elif isinstance(ipt, torch.Tensor):\n",
    "            if len(ipt.shape) == 4:\n",
    "                torch_form = inv_scipy_form2torch_form_2d(\n",
    "                    matrix,\n",
    "                    ipt_shape=ipt.shape[2:],\n",
    "                    trf_in_shape=trf_in_shape,\n",
    "                    trf_out_shape=trf_out_shape,\n",
    "                    out_shape=output_shape,\n",
    "                )\n",
    "            elif len(ipt.shape) == 5:\n",
    "                torch_form = inv_scipy_form2torch_form_3d(\n",
    "                    matrix,\n",
    "                    ipt_shape=ipt.shape[2:],\n",
    "                    trf_in_shape=trf_in_shape,\n",
    "                    trf_out_shape=trf_out_shape,\n",
    "                    out_shape=output_shape,\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(ipt.shape)\n",
    "\n",
    "            # affine_grid_size = tuple(ipt.shape[:2]) + output_shape\n",
    "            affine_grid_size = (1, 1) + output_shape\n",
    "            if self.affine_grid_size != affine_grid_size:\n",
    "                self.affine_torch_grid = torch.nn.functional.affine_grid(\n",
    "                    theta=torch_form, size=affine_grid_size, align_corners=False\n",
    "                )\n",
    "\n",
    "            on_cuda = ipt.is_cuda\n",
    "            if on_cuda != ipt.is_cuda:\n",
    "                if on_cuda:\n",
    "                    ipt = ipt.to(torch.device(\"cuda:0\"))\n",
    "                else:\n",
    "                    ipt = ipt.to(torch.device(\"cpu\"))\n",
    "\n",
    "            self.affine_torch_grid = self.affine_torch_grid.to(ipt)\n",
    "\n",
    "            if z_slices is None:\n",
    "                affine_grid = self.affine_torch_grid.repeat(ipt.shape[0], ipt.shape[1], 1, 1, 1)\n",
    "            else:\n",
    "                assert len(z_slices) == ipt.shape[0], (z_slices, ipt.shape)\n",
    "                assert all(self.z_offset <= z_slice for z_slice in z_slices), (self.z_offset, z_slices)\n",
    "                affine_grid = torch.cat(\n",
    "                    [\n",
    "                        self.affine_torch_grid[:, z_slice - self.z_offset : z_slice + 1 - self.z_offset]\n",
    "                        for z_slice in z_slices\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            ret = torch.nn.functional.grid_sample(\n",
    "                ipt, affine_grid, align_corners=False, mode=mode, padding_mode=\"border\"\n",
    "            )\n",
    "            if z_slices is not None:\n",
    "                assert ret.shape[2] == 1\n",
    "                ret = ret[:, :, 0]\n",
    "\n",
    "            if on_cuda == ipt.is_cuda:\n",
    "                return ret\n",
    "            elif ipt.is_cuda:\n",
    "                return ret.to(device=torch.device(\"cuda:0\"))\n",
    "            else:\n",
    "                return ret.to(device=torch.device(\"cpu\"))\n",
    "        else:\n",
    "            raise TypeError(type(ipt))\n",
    "\n",
    "    def ls2lf(self, ipt: Union[torch.Tensor, numpy.ndarray], **kwargs) -> Union[numpy.ndarray, torch.Tensor]:\n",
    "        raise NotImplementedError(\"trf_out_zoom\")\n",
    "        return self._ls2lf(\n",
    "            ipt, matrix=self.trf_matrix, trf_in_shape=self.ls_shape, trf_out_shape=self.lf_shape, **kwargs\n",
    "        )\n",
    "\n",
    "    def lf2ls(self, ipt: Union[torch.Tensor, numpy.ndarray], **kwargs) -> Union[numpy.ndarray, torch.Tensor]:\n",
    "        cropped_ls_shape: Union[Tuple[int, int], Tuple[int, int, int]] = tuple(\n",
    "            (lss - ls_crop[0] - ls_crop[1]) * zoom\n",
    "            for lss, ls_crop, zoom in zip(self.ls_shape, self.lf2ls_crop, self.trf_out_zoom)\n",
    "        )\n",
    "        return self._ls2lf(\n",
    "            ipt, matrix=self.lf2ls_matrix, trf_in_shape=self.lf_shape, trf_out_shape=cropped_ls_shape, **kwargs\n",
    "        )\n",
    "\n",
    "    \n",
    "class TestTransform(BDVTransform):\n",
    "    affine_transforms = ((0.98048,0.004709,0.098297,-111.7542,7.6415e-05,0.97546,0.0030523,-20.1143,0.014629,8.2964e-06,-3.9928,846.8515),)\n",
    "#     affine_transforms = (\n",
    "#             (\n",
    "#                 1.000045172184472,\n",
    "#                 -6.440948265626484e-4,\n",
    "#                 -0.0037246544505502403,\n",
    "#                 1.6647525184522693,\n",
    "#                 -3.741111751453333e-4,\n",
    "#                 0.9997241695263583,\n",
    "#                 -7.727988497216694e-6,\n",
    "#                 0.5482936082360137,\n",
    "#                 6.417439009031318e-4,\n",
    "#                 7.834754261221826e-5,\n",
    "#                 1.0024816523664135,\n",
    "#                 -2.0884853522301463,\n",
    "#             ),\n",
    "#             (\n",
    "#                 1.0031348487012806,\n",
    "#                 -2.4393612341215746e-4,\n",
    "#                 -0.022354095904371995,\n",
    "#                 5.848116160919745,\n",
    "#                 -5.688306131898453e-4,\n",
    "#                 1.0035215202352126,\n",
    "#                 0.005454826549562322,\n",
    "#                 -2.643832484309726,\n",
    "#                 0.009525454800378438,\n",
    "#                 -0.0040831532456764375,\n",
    "#                 1.0083740999442286,\n",
    "#                 -4.757593435405894,\n",
    "#             ),\n",
    "#             (\n",
    "#                 0.97669,\n",
    "#                 0.0076755,\n",
    "#                 0.0042258,\n",
    "#                 -95.112,\n",
    "#                 -0.0061276,\n",
    "#                 0.97912,\n",
    "#                 0.03892,\n",
    "#                 -134.1098,\n",
    "#                 0.007308,\n",
    "#                 0.0073582,\n",
    "#                 1.1682,\n",
    "#                 -92.7323,\n",
    "#             ),\n",
    "#             (1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.4185, 0.0),\n",
    "#         )\n",
    "#     affine_transforms = [\n",
    "# #     [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 17.029, 0.0],\n",
    "#     [0.98048, 0.004709, 0.028752, -111.7542, 7.6415E-5, 0.97546, 8.928E-4, -20.1143, 0.014629, 8.2964E-6, -1.1679, 846.8515],\n",
    "#     [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.4185, 0.0],\n",
    "#     ]\n",
    "    lf2ls_crop = ((0, 0), (0, 0), (0, 0))\n",
    "    ls_shape = (241, 1501, 1801)\n",
    "    lf_shape=(838, 1330, 1615)\n",
    "#     lf2ls_crop = ((23, 10), (130, 130), (100, 50))\n",
    "#     ls_shape = (241, 1451, 1951)\n",
    "#     lf_shape = (838, 1178, 1767)\n",
    "    \n",
    "old_trf = TestTransform(forward=\"lf2ls\", order=0, output_shape=(24, 150, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_out = old_trf(torch.from_numpy(sample[\"lr\"]).to(device=torch.device(\"cuda:0\"))).detach().cpu().numpy()[0, 0]\n",
    "old_out = old_trf(sample[\"lr\"][0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(old_out.max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(old_out.max(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(sample[\"ls\"][0, 0].max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(sample[\"ls\"][0, 0].max(1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = sample[\"ls\"][0, 0] - old_out\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(diff.max(0))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(diff.max(1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resized_registered_ls = zoom(registered_ls, [49/838, .1, .1])\n",
    "print(\"resized registered ls\", resized_registered_ls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(raw_ls.max(axis=0))\n",
    "plt.title(\"raw_ls\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(registered_ls.max(axis=0))\n",
    "plt.title(\"registered_ls\")\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(resized_registered_ls.max(axis=0))\n",
    "# plt.title(\"resized reg ls\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(numpy.abs(lf[20] - resized_registered_ls[20]))\n",
    "# plt.title(\"diff\")\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # y_shape = (241, 1451, 1651)\n",
    "# # trf_shape = (838, 1273 + 0, 1463 + 0)\n",
    "# trf_shape = \n",
    "# output_shape =  (838, 1273, 1463)\n",
    "# # output_shape = (838, 1451, 1651)\n",
    "# trf = AffineTransform(trf_shape=output_shape, output_shape=output_shape, order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(registered_ls.max(axis=0))\n",
    "# plt.title(\"registered_ls\")\n",
    "# plt.show()\n",
    "# \n",
    "# trf_shape = raw_ls.shape\n",
    "# output_shape = registered_ls.shape\n",
    "# print(\"trf_shape\", trf_shape, \"output_shape\", output_shape)\n",
    "# trf = AffineTransform(trf_shape=trf_shape, output_shape=output_shape, order=0)\n",
    "# \n",
    "# # plt.imshow(trf.forward_with_inverse(registered_ls).max(axis=0))\n",
    "# transformed_raw_ls = trf.forward_with_inverse(raw_ls)\n",
    "# plt.imshow(transformed_raw_ls.max(axis=0))\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LF2LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(raw_ls.max(axis=0))\n",
    "# plt.title(\"raw ls\")\n",
    "# plt.show()\n",
    "# plt.imshow(raw_ls.max(axis=1))\n",
    "# plt.show()\n",
    "# plt.imshow(raw_ls.max(axis=2))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# trf = AffineTransform(output_shape=raw_ls.shape, order=0)\n",
    "# \n",
    "# transformed_registered_ls = trf.lf2ls(registered_ls)\n",
    "# plt.imshow(transformed_registered_ls.max(axis=0))\n",
    "# plt.show()\n",
    "# plt.imshow(transformed_registered_ls.max(axis=1))\n",
    "# plt.show()\n",
    "# plt.imshow(transformed_registered_ls.max(axis=2))\n",
    "# plt.show()\n",
    "# \n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## resized LF2LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(resized_raw_ls.max(axis=0))\n",
    "plt.title(\"resized_raw_ls\")\n",
    "plt.show()\n",
    "plt.imshow(resized_raw_ls.max(axis=1))\n",
    "plt.title(\"resized_raw_ls\")\n",
    "plt.show()\n",
    "plt.imshow(resized_raw_ls.max(axis=2))\n",
    "plt.title(\"resized_raw_ls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outs = tuple(s // 2 for s in resized_raw_ls.shape)\n",
    "trf = AffineTransform(output_shape=outs, order=0)  # resized_raw_ls.shape\n",
    "transformed_registered_ls = trf.lf2ls(resized_registered_ls + .1)\n",
    "plt.imshow(transformed_registered_ls.max(axis=0))\n",
    "plt.show()\n",
    "plt.imshow(transformed_registered_ls.max(axis=1))\n",
    "plt.show()\n",
    "plt.imshow(transformed_registered_ls.max(axis=2))\n",
    "plt.show()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outs = tuple(s // 2 for s in resized_raw_ls.shape)\n",
    "trf = AffineTransform(output_shape=outs, order=0)  # resized_raw_ls.shape\n",
    "transformed_registered_ls = trf.lf2ls(resized_registered_ls + .1)\n",
    "plt.imshow(transformed_registered_ls.max(axis=0))\n",
    "plt.show()\n",
    "plt.imshow(transformed_registered_ls.max(axis=1))\n",
    "plt.show()\n",
    "plt.imshow(transformed_registered_ls.max(axis=2))\n",
    "plt.show()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(resized_raw_ls.max())\n",
    "print(transformed_registered_ls.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(numpy.abs(resized_raw_ls.max(axis=0) - transformed_registered_ls.max(axis=0)))\n",
    "plt.show()\n",
    "plt.imshow(numpy.abs(resized_raw_ls.max(axis=1) - transformed_registered_ls.max(axis=1)))\n",
    "plt.show()\n",
    "plt.imshow(numpy.abs(resized_raw_ls.max(axis=2) - transformed_registered_ls.max(axis=2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LS2LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(registered_ls.max(axis=0))\n",
    "plt.title(\"registered_ls\")\n",
    "plt.show()\n",
    "plt.imshow(registered_ls.max(axis=1))\n",
    "plt.show()\n",
    "plt.imshow(registered_ls.max(axis=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trf = AffineTransform(output_shape=registered_ls.shape, order=0)\n",
    "\n",
    "transformed_raw_ls = trf.ls2lf(raw_ls)\n",
    "plt.imshow(transformed_raw_ls.max(axis=0))\n",
    "plt.show()\n",
    "plt.imshow(transformed_raw_ls.max(axis=1))\n",
    "plt.show()\n",
    "plt.imshow(transformed_raw_ls.max(axis=2))\n",
    "plt.show()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## resized LS2LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resized_registered_ls = zoom(registered_ls, [.1, .1, .1])\n",
    "plt.imshow(resized_registered_ls.max(axis=0))\n",
    "plt.title(\"resized_registered_ls\")\n",
    "plt.show()\n",
    "plt.imshow(resized_registered_ls.max(axis=1))\n",
    "plt.show()\n",
    "plt.imshow(resized_registered_ls.max(axis=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trf = AffineTransform(output_shape=resized_registered_ls.shape, order=0)\n",
    "\n",
    "transformed_raw_ls = trf.ls2lf(raw_ls)\n",
    "plt.imshow(transformed_raw_ls.max(axis=0))\n",
    "plt.show()\n",
    "plt.imshow(transformed_raw_ls.max(axis=1))\n",
    "plt.show()\n",
    "plt.imshow(transformed_raw_ls.max(axis=2))\n",
    "plt.show()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
